{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863e8d8c-5106-4248-9582-bbf43738f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39741c13-f90e-43c6-874a-329c9d3b9a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/05 22:18:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://big-data-assignment-m.us-central1-c.c.affable-anagram-401023.internal:44687\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0bf24a56f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a Spark application\n",
    "spark = SparkSession.builder.appName('SparkBasics').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262fd392-1f2b-4c78-9781-00d23a71716d",
   "metadata": {},
   "source": [
    "### 1) PySpark environment and Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235e325-35c0-40eb-b0e1-a744dd0b84c9",
   "metadata": {},
   "source": [
    "a. Print the configuration settings of the PySpark environmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce851e5-baf7-4292-9541-acf76a5eefd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://qdxd6ahq2fdqbehoghgsusv574-dot-us-central1.dataproc.googleusercontent.com:80/gateway/default/yarn/proxy/application_1699123760114_0002'),\n",
       " ('spark.app.submitTime', '1699128252276'),\n",
       " ('spark.dataproc.sql.joinConditionReorder.enabled', 'true'),\n",
       " ('spark.dataproc.sql.local.rank.pushdown.enabled', 'true'),\n",
       " ('spark.yarn.unmanagedAM.enabled', 'true'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.metrics.namespace',\n",
       "  'app_name:${spark.app.name}.app_id:${spark.app.id}'),\n",
       " ('spark.driver.maxResultSize', '1024m'),\n",
       " ('spark.dataproc.sql.optimizer.leftsemijoin.conversion.enabled', 'true'),\n",
       " ('spark.hadoop.hive.execution.engine', 'mr'),\n",
       " ('spark.eventLog.dir',\n",
       "  'gs:/dataproc-temp-us-central1-798309803866-frmiwt84/69975949-d88e-46d5-9c93-a7f23d7f22f5/spark-job-history'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'PySparkShell'),\n",
       " ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'),\n",
       " ('spark.dynamicAllocation.maxExecutors', '10000'),\n",
       " ('spark.executor.memory', '2893m'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip:/usr/lib/spark/python/:<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9.5-src.zip'),\n",
       " ('spark.sql.catalogImplementation', 'hive'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.sql.parquet.enableNestedColumnVectorizedReader', 'true'),\n",
       " ('spark.executorEnv.OPENBLAS_NUM_THREADS', '1'),\n",
       " ('spark.yarn.historyServer.address', 'big-data-assignment-m:18080'),\n",
       " ('spark.sql.cbo.enabled', 'true'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.app.startTime', '1699128253739'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1699123760114_0002'),\n",
       " ('spark.dataproc.sql.parquet.enableFooterCache', 'true'),\n",
       " ('spark.sql.warehouse.dir', 'file:/spark-warehouse'),\n",
       " ('spark.sql.autoBroadcastJoinThreshold', '21m'),\n",
       " ('spark.yarn.am.memory', '640m'),\n",
       " ('spark.history.fs.logDirectory',\n",
       "  'gs:/dataproc-temp-us-central1-798309803866-frmiwt84/69975949-d88e-46d5-9c93-a7f23d7f22f5/spark-job-history'),\n",
       " ('spark.checkpoint.compress', 'true'),\n",
       " ('spark.driver.port', '39111'),\n",
       " ('spark.executor.instances', '2'),\n",
       " ('spark.dataproc.listeners',\n",
       "  'com.google.cloud.spark.performance.DataprocMetricsListener'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'big-data-assignment-m.us-central1-c.c.affable-anagram-401023.internal.'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.sql.cbo.joinReorder.enabled', 'true'),\n",
       " ('spark.app.id', 'application_1699123760114_0002'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.driver.appUIAddress',\n",
       "  'http:/big-data-assignment-m.us-central1-c.c.affable-anagram-401023.internal:38797'),\n",
       " ('spark.scheduler.mode', 'FAIR'),\n",
       " ('spark.sql.adaptive.enabled', 'true'),\n",
       " ('spark.yarn.jars', 'local:/usr/lib/spark/jars/*'),\n",
       " ('spark.scheduler.minRegisteredResourcesRatio', '0.0'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.memory', '2048m'),\n",
       " ('spark.ui.port', '0'),\n",
       " ('spark.rpc.message.maxSize', '512'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.driver.host',\n",
       "  'big-data-assignment-m.us-central1-c.c.affable-anagram-401023.internal'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad4399-789f-43b6-adf8-7d326ac84cbb",
   "metadata": {},
   "source": [
    "b. Read the Chicago crimes dataset into a PySpark datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7831ecdc-72a3-4722-8912-b0279ea5d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+--------------------+----+------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+\n",
      "|      ID|Case Number|                Date|               Block|IUCR|      Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|Latitude|Longitude|Location|\n",
      "+--------+-----------+--------------------+--------------------+----+------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+\n",
      "|11037294|   JA371270|03/18/2015 12:00:...|   0000X W WACKER DR|1153|DECEPTIVE PRACTICE|FINANCIAL IDENTIT...|                BANK| false|   false|0111|     001|  42|            32|      11|        null|        null|2015|08/01/2017 03:52:...|    null|     null|    null|\n",
      "|11646293|   JC213749|12/20/2018 03:00:...|023XX N LOCKWOOD AVE|1154|DECEPTIVE PRACTICE|FINANCIAL IDENTIT...|           APARTMENT| false|   false|2515|     025|  36|            19|      11|        null|        null|2018|04/06/2019 04:04:...|    null|     null|    null|\n",
      "|11645836|   JC212333|05/01/2016 12:25:...| 055XX S ROCKWELL ST|1153|DECEPTIVE PRACTICE|FINANCIAL IDENTIT...|                null| false|   false|0824|     008|  15|            63|      11|        null|        null|2016|04/06/2019 04:04:...|    null|     null|    null|\n",
      "|11645959|   JC211511|12/20/2018 04:00:...|  045XX N ALBANY AVE|2820|     OTHER OFFENSE|    TELEPHONE THREAT|           RESIDENCE| false|   false|1724|     017|  33|            14|     08A|        null|        null|2018|04/06/2019 04:04:...|    null|     null|    null|\n",
      "|11645601|   JC212935|06/01/2014 12:01:...| 087XX S SANGAMON ST|1153|DECEPTIVE PRACTICE|FINANCIAL IDENTIT...|           RESIDENCE| false|   false|2222|     022|  21|            71|      11|        null|        null|2014|04/06/2019 04:04:...|    null|     null|    null|\n",
      "+--------+-----------+--------------------+--------------------+----+------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"gs://gcs-de-2-annabella/Crimes_-_2001_to_Present.csv\", header=True)\n",
    "print(df.show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16121b56-2504-4fdd-a0c2-ab9dd5f2f80e",
   "metadata": {},
   "source": [
    "c. Print summary statistics of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "408f7e2b-056c-4167-85eb-574f5a99bb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+--------------+-----------------+-----------------+---------------+--------------------+-------+--------+-----------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|summary|                ID|       Case Number|                Date|         Block|             IUCR|     Primary Type|    Description|Location Description| Arrest|Domestic|             Beat|         District|              Ward|    Community Area|          FBI Code|      X Coordinate|     Y Coordinate|              Year|          Updated On|           Latitude|           Longitude|            Location|\n",
      "+-------+------------------+------------------+--------------------+--------------+-----------------+-----------------+---------------+--------------------+-------+--------+-----------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|  count|           7917278|           7917278|             7917278|       7917278|          7917278|          7917278|        7917278|             7905345|7917278| 7917278|          7917278|          7917231|           7302429|           7303802|           7917278|           7827086|          7827086|           7917278|             7917278|            7827086|             7827086|             7827086|\n",
      "|   mean| 7128316.344219187|299566.86666666664|                null|          null| 1119.97656680145|             null|           null|                null|   null|    null|1185.416285243489|11.29527432002426| 22.76055227650964| 37.46112873815583|12.056352263986678|1164612.8739284326|1885810.813258472|2010.1619339373963|                null| 41.842260113101524|  -87.67144968127596|                null|\n",
      "| stddev|3560921.2086232174|138492.54914247536|                null|          null|811.2441796692971|             null|           null|                null|   null|    null|703.3086770831123|6.955368545412692|13.852751655693089|21.542647669952004|7.3001665554628605|16842.677319327624|32274.05599173258| 6.428735347248071|                null|0.08879210131998454|0.061070583068153224|                null|\n",
      "|    min|              1000|         01G050460|01/01/2001 01:00:...|0000X E 100 PL|             0110|            ARSON| $300 AND UNDER|\"CTA \"\"L\"\" PLATFORM\"|  false|   false|             0111|              001|                 1|                 0|               01A|                 0|                0|              2001|01/01/2007 07:32:...|       36.619446395|       -87.524529378|(36.619446395, -9...|\n",
      "|    25%|         3841838.0|          161884.0|                null|          null|            560.0|             null|           null|                null|   null|    null|            621.0|              6.0|              10.0|              23.0|               6.0|         1152996.0|        1859096.0|            2005.0|                null|        41.76874464|       -87.713636218|                null|\n",
      "|    50%|         7127357.0|          318876.0|                null|          null|            860.0|             null|           null|                null|   null|    null|           1034.0|             10.0|              23.0|              32.0|              11.0|         1166133.0|        1890753.0|            2009.0|                null|       41.855983399|       -87.665784513|                null|\n",
      "|    75%|       1.0298741E7|          413567.0|                null|          null|           1320.0|             null|           null|                null|   null|    null|           1731.0|             17.0|              34.0|              57.0|              18.0|         1176389.0|        1909295.0|            2015.0|                null|        41.90683577|       -87.628153577|                null|\n",
      "|    max|           9999999|         ZZZ199957|12/31/2022 12:59:...|   XX  UNKNOWN|             9901|WEAPONS VIOLATION|WIREROOM/SPORTS|                YMCA|   true|    true|             2535|               16|                 9|                 9|                27|           1205119|          1951622|              2023|12/31/2022 03:42:...|       42.022910333|       -91.686565684|(42.022910333, -8...|\n",
      "+-------+------------------+------------------+--------------------+--------------+-----------------+-----------------+---------------+--------------------+-------+--------+-----------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0ced9-ea27-4922-9814-2baf56a59941",
   "metadata": {},
   "source": [
    "d. Inspect the data partitions and repartition if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98167abb-7a8d-4a70-9e14-b8908cad016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|partitionId| count|\n",
      "+-----------+------+\n",
      "|         13|522333|\n",
      "|          0|563918|\n",
      "|         12|565002|\n",
      "|         11|565438|\n",
      "|         10|566124|\n",
      "|          1|566449|\n",
      "|          9|566755|\n",
      "|          2|567841|\n",
      "|          7|567875|\n",
      "|          6|567927|\n",
      "|          8|568058|\n",
      "|          5|571033|\n",
      "|          3|572629|\n",
      "|          4|585896|\n",
      "+-----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#display number of records by partition\n",
    "def displaypartitions(df):\n",
    "    #number of records by partition\n",
    "    num = df.rdd.getNumPartitions()\n",
    "    print(\"Partitions:\", num)\n",
    "    df.withColumn(\"partitionId\", F.spark_partition_id())\\\n",
    "        .groupBy(\"partitionId\")\\\n",
    "        .count()\\\n",
    "        .orderBy(F.asc(\"count\"))\\\n",
    "        .show(num)\n",
    "displaypartitions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af100a12-41a7-4d7c-be3b-2068584b4791",
   "metadata": {},
   "source": [
    "### 2) Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07184a82-3710-4c28-92b9-dc9900090005",
   "metadata": {},
   "source": [
    "a. Drop the columns beat, ward, latitude and longitude column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df74b5b4-a754-49be-be20-2f91f132872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Beat','Ward','Latitude','Longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37558c3-ad7e-4ea8-bcdf-816b1a10a6b5",
   "metadata": {},
   "source": [
    "b. Convert remaining columns to appropriate data types. Make your best assumptions by sampling the\n",
    "data. View schema again to ensure that data types have been converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77983744-9e90-4fb4-bc5e-48b3b270d940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'string'),\n",
       " ('Case Number', 'string'),\n",
       " ('Date', 'string'),\n",
       " ('Block', 'string'),\n",
       " ('IUCR', 'string'),\n",
       " ('Primary Type', 'string'),\n",
       " ('Description', 'string'),\n",
       " ('Location Description', 'string'),\n",
       " ('Arrest', 'string'),\n",
       " ('Domestic', 'string'),\n",
       " ('District', 'string'),\n",
       " ('Community Area', 'string'),\n",
       " ('FBI Code', 'string'),\n",
       " ('X Coordinate', 'string'),\n",
       " ('Y Coordinate', 'string'),\n",
       " ('Year', 'string'),\n",
       " ('Updated On', 'string'),\n",
       " ('Location', 'string')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e923da96-420f-4564-b8d5-ab9d8f2b9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, from_unixtime\n",
    "df = df.select('Date', from_unixtime(unix_timestamp('Date', 'MM-dd-yyyy HH:mm:ss')).alias('Date_n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e65215-6212-4271-8165-fd4ff5114e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====================================================>    (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Date_n|\n",
      "+------+\n",
      "|  null|\n",
      "+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select('Date_n').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a5743341-92c4-4135-ad3d-687f8a0e299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import BooleanType\n",
    "df = df.withColumn('Arrest', F.col('Arrest').cast(BooleanType()))\n",
    "df = df.withColumn('Domestic', F.col('Domestic').cast(BooleanType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2dbf6151-5ab3-4512-9e39-d2b425fa0c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: boolean (nullable = true)\n",
      " |-- Domestic: boolean (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Community Area: string (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: string (nullable = true)\n",
      " |-- Y Coordinate: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Updated On: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e18b9e-f88e-4598-8bd5-ad02eb1a3cf9",
   "metadata": {},
   "source": [
    "c. Add a month column and community name (from metadata) to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2bae7faf-98e7-49e7-a36e-ee8a5bb11ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a month column\n",
    "from pyspark.sql.functions import month\n",
    "df = df.withColumn('Month', month(df.Date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf685638-1f15-401e-bba6-037d1363ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add community name column\n",
    "from pyspark.sql.functions import lit\n",
    "name = ['ROGERS PARK','WEST RIDGE','UPTOWN','LINCOLN SQUARE','NORTH CENTER','LAKE VIEW','LINCOLN PARK','NEAR NORTH SIDE','EDISON PARK','NORWOOD PARK','JEFFERSON PARK','FOREST GLEN','NORTH PARK','ALBANY PARK','PORTAGE PARK','IRVING PARK','DUNNING','MONTCLARE','BELMONT CRAGIN','HERMOSA','AVONDALE',\n",
    "        'LOGAN SQUARE','HUMBOLDT PARK','WEST TOWN','AUSTIN','WEST GARFIELD PARK','EAST GARFIELD PARK','NEAR WEST SIDE','NORTH LAWNDALE','SOUTH LAWNDALE','LOWER WEST SIDE','LOOP','NEAR SOUTH SIDE','ARMOUR SQUARE','DOUGLAS','OAKLAND','FULLER PARK','GRAND BOULEVARD','KENWOOD','WASHINGTON PARK','HYDE PARK',\n",
    "        'WOODLAWN','SOUTH SHORE','CHATHAM','AVALON PARK','SOUTH CHICAGO','BURNSIDE','CALUMET HEIGHTS','ROSELAND','PULLMAN','SOUTH DEERING','EAST SIDE','WEST PULLMAN','RIVERDALE','HEGEWISCH','GARFIELD RIDGE','ARCHER HEIGHTS','BRIGHTON PARK','MCKINLEY PARK','BRIDGEPORT','NEW CITY','WEST ELSDON','GAGE PARK',\n",
    "        'CLEARING','WEST LAWN','CHICAGO LAWN','WEST ENGLEWOOD','ENGLEWOOD','GREATER GRAND CROSSING','ASHBURN','AUBURN GRESHAM','BEVERLY','WASHINGTON HEIGHTS','MOUNT GREENWOOD','MORGAN PARK','OHARE','EDGEWATER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f737af45-00b4-4751-9918-86d773e701ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "Conditional_values = [(df['Community Area'] == i, name[i]) for i in range(len(name))]\n",
    "for c, n in Conditional_values:\n",
    "    df = df.withColumn('Community Name', when(c,n).otherwise(F.col('Community Name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e9366b1-6f53-443b-9b10-f48832ec2b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: boolean (nullable = true)\n",
      " |-- Domestic: boolean (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Community Area: string (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: string (nullable = true)\n",
      " |-- Y Coordinate: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Updated On: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Community Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca32355-eecb-47f7-8526-e077e073cdbb",
   "metadata": {},
   "source": [
    "### 3) Explore data by crime attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68592ffe-9cea-4fa6-b462-0ce9c06abfca",
   "metadata": {},
   "source": [
    "a. Group and count crimes where description begins with the word “aggravated”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5830dd85-0ce3-4709-84a7-b936b47ebca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:====================================================>    (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        Primary Type| count|\n",
      "+--------------------+------+\n",
      "|OFFENSE INVOLVING...|  2729|\n",
      "|CRIMINAL SEXUAL A...|  1585|\n",
      "|            STALKING|   151|\n",
      "|               ARSON|  2076|\n",
      "|             ASSAULT|139016|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "Agg = df.filter(\"Description like 'AGGRAVATED%'\").groupby('Primary Type').count()\n",
    "Agg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0b1ad-b50e-4911-b607-d10c451970f0",
   "metadata": {},
   "source": [
    "b. Which crime type is the most prevalent in apartments and which community has it occurred the mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a134bb9a-aa77-4a86-8ef9-6ae093a0bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|Primary Type| count|\n",
      "+------------+------+\n",
      "|     BATTERY|306264|\n",
      "+------------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(df['Location Description']=='APARTMENT').groupby('Primary Type').count().orderBy(['count'], ascending=[0]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "229e3b28-aa1f-4cc1-a59b-f3ec3c53f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|    Community Name| count|\n",
      "+------------------+------+\n",
      "|              null|130482|\n",
      "|WEST GARFIELD PARK| 91900|\n",
      "+------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(df['Primary Type'] == 'BATTERY').groupby('Community Name').count().orderBy(['count'],ascending=[0]).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb221371-6874-4120-b43a-045e61b502cd",
   "metadata": {},
   "source": [
    "c. What is the maximum number of weapons violations per month that occurred in 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ef6ea88-f03d-4937-b42b-7f4862f22aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|      8432|\n",
      "+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "df.filter(df['Year'] == 2020).filter(df['Primary Type'] == 'WEAPONS VIOLATION').groupby('Month').count().agg(F.max('count')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9c739-5583-4384-9923-17d5544903e3",
   "metadata": {},
   "source": [
    "d. What percentage of the domestic crimes led to an arrest ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "63d4476f-7702-4906-b393-dc35588a5fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|Domestic|  count|\n",
      "+--------+-------+\n",
      "|    true| 265354|\n",
      "|   false|1785151|\n",
      "+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dom_arrest = df.filter(df['Arrest']==True).groupby('Domestic').count()\n",
    "dom_arrest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f6b3da5-a1bd-464b-aa7f-15c36cb9fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of the domestic crimes led to an arrest: 14.86451286193717 %\n"
     ]
    }
   ],
   "source": [
    "per = 265354 * 100 / 1785151\n",
    "print(f'percentage of the domestic crimes led to an arrest: {per} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873894d0-6b03-4c59-a428-4b39a6e2fa50",
   "metadata": {},
   "source": [
    "### 4) Explore data by date and time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895aebce-0ddf-4792-a069-07b05213e7e0",
   "metadata": {},
   "source": [
    "a. Which day of the week and which month have the most and the least crimes on averag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bb3b26b0-d451-4bf3-a466-2e1fa8b73a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|Month|  count|\n",
      "+-----+-------+\n",
      "| null|7917278|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Month\n",
    "df.groupby('Month').count().orderBy(['count'], ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845b2a9-ee8e-47d0-a08b-d03970e72477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Day of week\n",
    "from pyspark.sql.functions import date_format\n",
    "df = df.withColumn(\"DayOfWeek\", date_format(F.col(\"Date\"), \"E\"))\n",
    "df.groupby('DayOfWeek').count().orderBy(['count'], ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d822a8-fbd9-4ec6-8f63-e48de61bc1e7",
   "metadata": {},
   "source": [
    "b. Which date had the most number of homicides in the dataset. How many days passed between this date\n",
    "and the next highest number of homicides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96378560-e044-475f-a546-860bba7ea7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(df['Primary Type'=='HOMICIDES']).groupby('DayOfWeek').count().orderBy(['count'], ascending=[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c889d3-1e98-4fad-b7d0-0708633617c1",
   "metadata": {},
   "source": [
    "c. Plot a monthly time series line chart of all crimes for the last 3 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc8cbc-c080-49f0-959b-bc6fd7f2b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mon_crime = df.filter(df['Year']==2023 & df['Year']==2022 & df['Year']==2021).groupby('Year','Month').count().orderBy([\"Year\", \"Month\"], ascending=[0, 0])\n",
    "pl = mon_crime.toPandas()\n",
    "pl.plot(y=\"count\", figsize=(15,4), style=\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c66a0-fc7c-41cd-8916-f5c151341019",
   "metadata": {},
   "source": [
    "d. Plot a year over year comparison for 3 years (2020, 2021, 2022) by top 5 crime types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181bb33a-efcc-4f32-b42c-8df4c5ca7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_type = df.filter(df['Year']==2023 & df['Year']==2022 & df['Year']==2021).groupby('Primary Type').count().order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda888f-f199-46c7-b318-181858045bae",
   "metadata": {},
   "source": [
    "### 5) Explore by location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a17a12b-65de-4fa9-89f7-7a3b97a7572d",
   "metadata": {},
   "source": [
    "a. Use a window function to calculate the community rank based on total crime figures (highest to lowest),\n",
    "where the community with the highest crime will have rank 1. Your results set should have 1 row for\n",
    "each community, with a column for the community name and the rank. You can also add a column with\n",
    "the total crime count if it helps you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a6938-ac91-4b90-a01f-0b7af3617a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb273a0c-5f7b-4d8f-9e5c-72b18d96dc32",
   "metadata": {},
   "source": [
    "b. Use a window function to calculate a rolling 7 day sum of crimes over time within each community Your\n",
    "results set should have 3 columns: community, date, and the rolling/lagging 7 day sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1a1b4-903c-444e-b24e-f7a65bf3bf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96ea0f5d-fbf7-4efb-8a32-db855831b196",
   "metadata": {},
   "source": [
    "c. Use window functions to calculate a 7 day moving average and cumulative sum of crimes over\n",
    "time within each community. Your results set should have 4 columns: community, date, the 7 day\n",
    "moving average, and the cumulative sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693df9c-0c40-4645-8e4e-d58c7ccf692b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6fca6d8-e738-4bd9-aff7-2e148421128c",
   "metadata": {},
   "source": [
    "d. Cross-tabulate Crime Types vs Location description and visualize it through a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b9036-3d28-49f0-941c-fa2799a42d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4965a831-bb39-45ee-ae72-2ace4e5f0486",
   "metadata": {},
   "source": [
    "### 6) Impact of Covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10f91f-d93a-4771-be4c-9dec5e328ae8",
   "metadata": {},
   "source": [
    "a. Bring in daily Covid cases data from the City of Chicago data portal and load into your data lake or Hive\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217582c-a311-4756-83eb-c3d7168d9c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82532841-9c94-45e6-8d7c-a0d04d379901",
   "metadata": {},
   "source": [
    "b. Create summarized daily total counts of the daily crime data by crime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb607544-6210-47bf-8385-e46a7f6a59c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5e21668-3147-423a-a8c9-64d39abc1d2e",
   "metadata": {},
   "source": [
    "c. Join daily total covid cases and death data with daily chicago crimes data starting Jan 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d3b3b-8af6-431a-895c-b3fc5a5acbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9168d6f9-755b-482f-9451-d6e04a6b8ade",
   "metadata": {},
   "source": [
    "d. Perform a thorough analysis in PySpark on how Covid-19 has impacted various types of crimes\n",
    "compared to previous years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64201d8b-0e4f-46d8-ac26-f9d51f47c635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
